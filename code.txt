from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from uuid import uuid4
from datetime import datetime

app = FastAPI(title="Book Review Service", description="API for managing books and their reviews", version="1.0.0")

# Data models
class Book(BaseModel):
    id: str
    title: str
    author: str
    publication_year: int

class Review(BaseModel):
    id: str
    book_id: str
    rating: int
    comment: Optional[str]
    created_at: datetime

# In-memory storage
books = []
reviews = []

# Book endpoints
@app.get("/books", response_model=List[Book], summary="List all books", description="Retrieve a list of all books in the system.")
async def get_books():
    return books

@app.post("/books", response_model=Book, status_code=201, summary="Add a new book", description="Create a new book with title, author, and publication year.")
async def add_book(book: Book):
    book.id = str(uuid4())
    books.append(book)
    return book

# Review endpoints
@app.get("/books/{book_id}/reviews", response_model=List[Review], summary="List reviews for a book", description="Retrieve all reviews for a specific book by its ID.")
async def get_reviews(book_id: str):
    if not any(book.id == book_id for book in books):
        raise HTTPException(status_code=404, detail="Book not found")
    return [review for review in reviews if review.book_id == book_id]

@app.post("/books/{book_id}/reviews", response_model=Review, status_code=201, summary="Add a review for a book", description="Create a new review for a specific book with a rating and optional comment.")
async def add_review(book_id: str, review: Review):
    if not any(book.id == book_id for book in books):
        raise HTTPException(status_code=404, detail="Book not found")
    if not (1 <= review.rating <= 5):
        raise HTTPException(status_code=400, detail="Rating must be between 1 and 5")
    review.id = str(uuid4())
    review.book_id = book_id
    review.created_at = datetime.utcnow()
    reviews.append(review)
    return review


# models.py
from sqlalchemy import Column, Integer, String, Text, Float, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Book(Base):
    __tablename__ = 'books'
    id = Column(Integer, primary_key=True)
    title = Column(String(255), nullable=False)
    author = Column(String(100), nullable=False)
    reviews = relationship('Review', backref='book')

class Review(Base):
    __tablename__ = 'reviews'
    id = Column(Integer, primary_key=True)
    book_id = Column(Integer, ForeignKey('books.id'), nullable=False)
    user_id = Column(Integer, nullable=False)
    rating = Column(Float, nullable=False)
    comment = Column(Text)

alembic init migrations
[alembic]
script_location = migrations
sqlalchemy.url = postgresql://user:password@localhost:5432/library

from alembic import op
import sqlalchemy as sa

def upgrade():
    # Create books table
    op.create_table(
        'books',
        sa.Column('id', sa.Integer, primary_key=True),
        sa.Column('title', sa.String(255), nullable=False),
        sa.Column('author', sa.String(100), nullable=False)
    )
    
    # Create reviews table
    op.create_table(
        'reviews',
        sa.Column('id', sa.Integer, primary_key=True),
        sa.Column('book_id', sa.Integer, sa.ForeignKey('books.id'), nullable=False),
        sa.Column('user_id', sa.Integer, nullable=False),
        sa.Column('rating', sa.Float, nullable=False),
        sa.Column('comment', sa.Text)
    )
    
    # Create index on book_id in reviews table
    op.create_index('idx_reviews_book_id', 'reviews', ['book_id'])

def downgrade():
    op.drop_index('idx_reviews_book_id')
    op.drop_table('reviews')
    op.drop_table('books')

# main.py
from sqlalchemy.orm import Session
from database import SessionLocal, init_db
from models import Book, Review

def add_book_and_review(db: Session, title: str, author: str, rating: float, comment: str):
    book = Book(title=title, author=author)
    db.add(book)
    db.flush()  # Get book.id before committing
    
    review = Review(book_id=book.id, user_id=1, rating=rating, comment=comment)
    db.add(review)
    db.commit()
    return book, review

# Initialize database
init_db()

# Example usage
with SessionLocal() as db:
    book, review = add_book_and_review(
        db,
        title="The Great Novel",
        author="John Doe",
        rating=4.5,
        comment="Amazing read!"
    )
    
    # Query reviews by book (optimized by index)
    reviews = db.query(Review).filter(Review.book_id == book.id).all()

3.
from sqlalchemy.orm import Session
from database import SessionLocal, init_db
from models import Book, Review
import redis
import json
import logging
from contextlib import contextmanager
from typing import List, Optional
from sqlalchemy.exc import SQLAlchemyError

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Mock Redis client (for demonstration; replace with actual redis.Redis() in production)
class MockRedis:
    def __init__(self):
        self._cache = {}

    def get(self, key):
        return self._cache.get(key)

    def set(self, key, value, ex=None):
        self._cache[key] = value

    def ping(self):
        return True  # Simulate successful connection

# Initialize Redis client
try:
    cache = MockRedis()
    cache.ping()  # Check connection
except redis.RedisError as e:
    logger.error(f"Failed to connect to Redis: {e}")
    cache = None  # Fallback to no cache if connection fails

@contextmanager
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def serialize_book(book: Book) -> dict:
    return {
        "id": book.id,
        "title": book.title,
        "author": book.author
    }

def deserialize_book(data: bytes) -> dict:
    return json.loads(data.decode('utf-8'))

def get_books_from_cache(book_id: Optional[int] = None) -> List[dict]:
    try:
        if cache is None:
            logger.warning("Cache unavailable, falling back to database")
            return None

        if book_id:
            cache_key = f"book:{book_id}"
            cached = cache.get(cache_key)
            if cached:
                logger.info(f"Cache hit for book_id: {book_id}")
                return [deserialize_book(cached)]
            logger.info(f"Cache miss for book_id: {book_id}")
            return None
        else:
            # For simplicity, assume we store all books under a single key
            cached = cache.get("books:all")
            if cached:
                logger.info("Cache hit for all books")
                return deserialize_book(cached)
            logger.info("Cache miss for all books")
            return None
    except redis.RedisError as e:
        logger.error(f"Cache read error: {e}")
        return None

def set_books_to_cache(books: List[dict], book_id: Optional[int] = None):
    try:
        if cache is None:
            logger.warning("Cache unavailable, skipping cache set")
            return

        if book_id:
            cache_key = f"book:{book_id}"
            cache.set(cache_key, json.dumps(books[0]).encode('utf-8'), ex=3600)
            logger.info(f"Cached book_id: {book_id}")
        else:
            cache.set("books:all", json.dumps(books).encode('utf-8'), ex=3600)
            logger.info("Cached all books")
    except redis.RedisError as e:
        logger.error(f"Cache write error: {e}")

def get_books(book_id: Optional[int] = None) -> List[dict]:
    # Try cache first
    cached_books = get_books_from_cache(book_id)
    if cached_books:
        return cached_books

    # Cache miss or cache unavailable, query database
    try:
        with get_db() as db:
            query = db.query(Book)
            if book_id:
                query = query.filter(Book.id == book_id)
            books = query.all()

            if not books:
                logger.info(f"No books found for book_id: {book_id}" if book_id else "No books found")
                return []

            # Serialize books for caching and response
            result = [serialize_book(book) for book in books]

            # Update cache
            set_books_to_cache(result, book_id)
            return result
    except SQLAlchemyError as e:
        logger.error(f"Database error: {e}")
        raise Exception("Failed to fetch books from database")

def add_book_and_review(db: Session, title: str, author: str, rating: float, comment: str):
    try:
        book = Book(title=title, author=author)
        db.add(book)
        db.flush()  # Get book.id before committing

        review = Review(book_id=book.id, user_id=1, rating=rating, comment=comment)
        db.add(review)
        db.commit()

        # Invalidate cache for books
        try:
            if cache:
                cache.set("books:all", None)  # Clear all books cache
                logger.info("Invalidated books:all cache")
        except redis.RedisError as e:
            logger.error(f"Cache invalidation error: {e}")

        return book, review
    except SQLAlchemyError as e:
        db.rollback()
        logger.error(f"Database error during add: {e}")
        raise Exception("Failed to add book and review")

# Example usage
if __name__ == "__main__":
    init_db()
    
    # Add a book and review
    with get_db() as db:
        try:
            book, review = add_book_and_review(
                db,
                title="The Great Novel",
                author="John Doe",
                rating=4.5,
                comment="Amazing read!"
            )
            print(f"Added book: {book.title}")
        except Exception as e:
            print(f"Error: {e}")

    # Fetch books
    try:
        books = get_books()
        print(f"Fetched books: {[book['title'] for book in books]}")
        
        # Fetch specific book
        book = get_books(book_id=1)
        print(f"Fetched book: {book[0]['title'] if book else 'Not found'}")
    except Exception as e:
        print(f"Error: {e}")



4
import unittest

class TestLibraryAPI(unittest.TestCase):
    def setUp(self):
        # Initialize in-memory SQLite for testing
        self.db_url = "sqlite:///:memory:"
        from database import create_engine
        self.engine = create_engine(self.db_url)
        init_db()  # Create tables
        
        # Mock Redis
        self.mock_redis = MockRedis()
        
        # Patch the cache in main.py
        self.redis_patcher = patch('main.cache', self.mock_redis)
        self.redis_patcher.start()
        
    def tearDown(self):
        # Clean up database
        with get_db() as db:
            db.query(Review).delete()
            db.query(Book).delete()
            db.commit()
        self.redis_patcher.stop()

    def test_get_books_endpoint_empty(self):
        """Test get_books endpoint when no books exist"""
        result = get_books()
        self.assertEqual(result, [], "Expected empty list when no books exist")
        
        # Verify cache was checked
        self.assertIsNone(self.mock_redis.get("books:all"), "Cache should be empty")

    def test_get_books_endpoint_with_data(self):
        """Test get_books endpoint with existing books"""
        with get_db() as db:
            book = Book(title="Test Book", author="Test Author")
            db.add(book)
            db.commit()
        
        result = get_books()
        self.assertEqual(len(result), 1, "Expected one book in result")
        self.assertEqual(result[0]["title"], "Test Book", "Book title mismatch")
        self.assertEqual(result[0]["author"], "Test Author", "Book author mismatch")
        
        # Verify cache was updated
        cached = self.mock_redis.get("books:all")
        self.assertIsNotNone(cached, "Cache should have been populated")
        cached_books = json.loads(cached.decode('utf-8'))
        self.assertEqual(cached_books[0]["title"], "Test Book", "Cached book title mismatch")

    def test_add_book_and_review_endpoint(self):
        """Test add_book_and_review endpoint"""
        with get_db() as db:
            book, review = add_book_and_review(
                db,
                title="New Book",
                author="New Author",
                rating=4.0,
                comment="Great read!"
            )
            self.assertEqual(book.title, "New Book", "Book title mismatch")
            self.assertEqual(book.author, "New Author", "Book author mismatch")
            self.assertEqual(review.rating, 4.0, "Review rating mismatch")
            self.assertEqual(review.comment, "Great read!", "Review comment mismatch")
            
            # Verify cache invalidation
            self.assertIsNone(self.mock_redis.get("books:all"), "Cache should be invalidated")

    def test_integration_cache_miss(self):
        """Integration test for cache-miss path"""
        # Simulate cache miss
        self.mock_redis.get = MagicMock(return_value=None)
        
        with get_db() as db:
            # Add a book to the database
            book = Book(title="Cache Miss Book", author="Cache Author")
            db.add(book)
            db.commit()
            book_id = book.id
        
        # Fetch books, triggering cache miss
        with patch.object(self.mock_redis, 'set') as mock_set:
            result = get_books(book_id=book_id)
            
            # Verify database was queried
            self.assertEqual(len(result), 1, "Expected one book in result")
            self.assertEqual(result[0]["title"], "Cache Miss Book", "Book title mismatch")
            
            # Verify cache was updated
            mock_set.assert_called_once()
            call_args = mock_set.call_args[0]
            self.assertEqual(call_args[0], f"book:{book_id}", "Cache key incorrect")
            cached_book = json.loads(call_args[1].decode('utf-8'))
            self.assertEqual(cached_book["title"], "Cache Miss Book", "Cached book title mismatch")

if __name__ == '__main__':
    unittest.main()


